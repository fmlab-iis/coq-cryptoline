proc main(uint64 a0_0, uint64 a1_0, uint64 a2_0, uint64 a3_0, uint64 a4_0, uint64 b0_0, uint64 b1_0, uint64 b2_0, uint64 b3_0, uint64 b4_0) =
{ true && and [a0_0 <u 9007199254740992@64, a1_0 <u 9007199254740992@64, a2_0 <u 9007199254740992@64, a3_0 <u 9007199254740992@64, a4_0 <u 9007199254740992@64, b0_0 <u 9007199254740992@64, b1_0 <u 9007199254740992@64, b2_0 <u 9007199254740992@64, b3_0 <u 9007199254740992@64, b4_0 <u 9007199254740992@64] }
mov in166_0_1 a0_0;
mov in166_8_1 a1_0;
mov in166_16_1 a2_0;
mov in166_24_1 a3_0;
mov in166_32_1 a4_0;
mov in272_0_1 b0_0;
mov in272_8_1 b1_0;
mov in272_16_1 b2_0;
mov in272_24_1 b3_0;
mov in272_32_1 b4_0;
mov x1067_1 in166_32_1;
mov x1168_1 in166_24_1;
mov x969_1 in166_16_1;
mov x770_1 in166_8_1;
mov x571_1 in166_0_1;
mov x1873_1 in272_32_1;
mov x1974_1 in272_24_1;
mov x1775_1 in272_16_1;
mov x1576_1 in272_8_1;
mov x1377_1 in272_0_1;
mulj x2078_1 x571_1 x1377_1;
mulj v4_1 x571_1 x1576_1;
mulj v6_1 x1377_1 x770_1;
mulj v8_1 x571_1 x1775_1;
mulj v10_1 x1377_1 x969_1;
mulj v12_1 x1576_1 x770_1;
mulj v14_1 x571_1 x1974_1;
mulj v16_1 x1377_1 x1168_1;
add v119_1 v14_1 v16_1;
mulj v18_1 x1576_1 x969_1;
mulj v19_1 x770_1 x1775_1;
add v120_1 v18_1 v119_1;
add x2381_1 v19_1 v120_1;
mulj v22_1 x571_1 x1873_1;
mulj v24_1 x1377_1 x1067_1;
add v116_1 v22_1 v24_1;
mulj v26_1 x770_1 x1974_1;
mulj v27_1 x1576_1 x1168_1;
add v115_1 v26_1 v116_1;
add v29_1 v27_1 v115_1;
mulj v30_1 x1775_1 x969_1;
add x2482_1 v29_1 v30_1;
mul x2583_1 x1067_1 19@uint64;
mul x2684_1 x770_1 19@uint64;
mul x2785_1 x969_1 19@uint64;
mul x2886_1 x1168_1 19@uint64;
mulj v32_1 x1576_1 x2583_1;
mulj v34_1 x1873_1 x2684_1;
add v35_1 v32_1 v34_1;
add v36_1 v35_1 x2078_1;
mulj v38_1 x1775_1 x2886_1;
mulj v40_1 x1974_1 x2785_1;
add v130_1 v36_1 v38_1;
add x2987_1 v40_1 v130_1;
mulj v42_1 x1775_1 x2583_1;
mulj v43_1 x1873_1 x2785_1;
add v127_1 v4_1 v6_1;
add v128_1 v42_1 v127_1;
add v45_1 v43_1 v128_1;
mulj v46_1 x1974_1 x2886_1;
add x3088_1 v45_1 v46_1;
mulj v47_1 x1974_1 x2583_1;
mulj v48_1 x1873_1 x2886_1;
add v123_1 v8_1 v10_1;
add v124_1 v12_1 v123_1;
add v125_1 v47_1 v124_1;
add x3189_1 v48_1 v125_1;
mulj v50_1 x1873_1 x2583_1;
add x3290_1 v50_1 x2381_1;
split v51_1 tmp_to_use_1 x2987_1 51;
cast v52_1@uint64 x2987_1;
and x3491_1@uint64 v52_1 2251799813685247@uint64;
vpc tmp_to_use_p_1@uint64 tmp_to_use_1;
assume x3491_1 = tmp_to_use_1 && true;
mov value_lo_1 18446744073709551615@uint64;
mov value_hi_1 0@uint64;
join value_1 value_hi_1 value_lo_1;
and v63_1@uint128 v51_1 value_1;
assume v63_1 = v51_1 && true;
add x3592_1 v63_1 x3088_1;
split v53_1 tmp_to_use_2 x3592_1 51;
cast v54_1@uint64 x3592_1;
and x3793_1@uint64 v54_1 2251799813685247@uint64;
vpc tmp_to_use_p_2@uint64 tmp_to_use_2;
assume x3793_1 = tmp_to_use_2 && true;
mov value_lo_2 18446744073709551615@uint64;
mov value_hi_2 0@uint64;
join value_2 value_hi_2 value_lo_2;
and v64_1@uint128 v53_1 value_2;
assume v64_1 = v53_1 && true;
add x3894_1 v64_1 x3189_1;
split v55_1 tmp_to_use_3 x3894_1 51;
cast v56_1@uint64 x3894_1;
and x4095_1@uint64 v56_1 2251799813685247@uint64;
vpc tmp_to_use_p_3@uint64 tmp_to_use_3;
assume x4095_1 = tmp_to_use_3 && true;
mov value_lo_3 18446744073709551615@uint64;
mov value_hi_3 0@uint64;
join value_3 value_hi_3 value_lo_3;
and v113_1@uint128 v55_1 value_3;
assume v113_1 = v55_1 && true;
add x4196_1 x3290_1 v113_1;
split v57_1 tmp_to_use_4 x4196_1 51;
cast v58_1@uint64 x4196_1;
and x4397_1@uint64 v58_1 2251799813685247@uint64;
vpc tmp_to_use_p_4@uint64 tmp_to_use_4;
assume x4397_1 = tmp_to_use_4 && true;
mov value_lo_4 18446744073709551615@uint64;
mov value_hi_4 0@uint64;
join value_4 value_hi_4 value_lo_4;
and v114_1@uint128 v57_1 value_4;
assume v114_1 = v57_1 && true;
add x4498_1 x2482_1 v114_1;
split v59_1 tmp_to_use_5 x4498_1 51;
vpc x4599_1@uint64 v59_1;
cast v60_1@uint64 x4498_1;
and x46100_1@uint64 v60_1 2251799813685247@uint64;
vpc tmp_to_use_p_5@uint64 tmp_to_use_5;
assume x46100_1 = tmp_to_use_5 && true;
mul v61_1 x4599_1 19@uint64;
add x47101_1 v61_1 x3491_1;
split x48102_1 tmp_to_use_6 x47101_1 51;
and x49103_1@uint64 x47101_1 2251799813685247@uint64;
vpc tmp_to_use_p_6@uint64 tmp_to_use_6;
assume x49103_1 = tmp_to_use_6 && true;
add x50104_1 x3793_1 x48102_1;
split x51105_1 tmp_to_use_7 x50104_1 51;
and x52106_1@uint64 x50104_1 2251799813685247@uint64;
vpc tmp_to_use_p_7@uint64 tmp_to_use_7;
assume x52106_1 = tmp_to_use_7 && true;
mov out107_0_1 x49103_1;
mov out107_8_1 x52106_1;
add v62_1 x4095_1 x51105_1;
mov out107_16_1 v62_1;
mov out107_24_1 x4397_1;
mov out107_32_1 x46100_1;
mov c0_1 out107_0_1;
mov c1_1 out107_8_1;
mov c2_1 out107_16_1;
mov c3_1 out107_24_1;
mov c4_1 out107_32_1;
{ c0_1 + (c1_1 * 2251799813685248) + (c2_1 * 5070602400912917605986812821504) + (c3_1 * 11417981541647679048466287755595961091061972992) + (c4_1 * 25711008708143844408671393477458601640355247900524685364822016) = (a0_0 + (a1_0 * 2251799813685248) + (a2_0 * 5070602400912917605986812821504) + (a3_0 * 11417981541647679048466287755595961091061972992) + (a4_0 * 25711008708143844408671393477458601640355247900524685364822016)) * (b0_0 + (b1_0 * 2251799813685248) + (b2_0 * 5070602400912917605986812821504) + (b3_0 * 11417981541647679048466287755595961091061972992) + (b4_0 * 25711008708143844408671393477458601640355247900524685364822016)) (mod 57896044618658097711785492504343953926634992332820282019728792003956564819968 - 19) && and [x3491_1 = tmp_to_use_p_1, v63_1 = v51_1, x3793_1 = tmp_to_use_p_2, v64_1 = v53_1, x4095_1 = tmp_to_use_p_3, v113_1 = v55_1, x4397_1 = tmp_to_use_p_4, v114_1 = v57_1, x46100_1 = tmp_to_use_p_5, x49103_1 = tmp_to_use_p_6, x52106_1 = tmp_to_use_p_7, c0_1 <u 2251799813718016@64, c1_1 <u 2251799813718016@64, c2_1 <u 2251799813718016@64, c3_1 <u 2251799813718016@64, c4_1 <u 2251799813718016@64] }
